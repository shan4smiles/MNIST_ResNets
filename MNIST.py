# -*- coding: utf-8 -*-
"""Untitled18.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Wmn00m-RJljZxwqRtFOiTcix1eOEhB-j
"""



"""# MNIST recognition

# Data Generation
"""

# from tensorflow MNSIT
import tensorflow as tf
from tensorflow.keras.datasets import mnist

dataset = mnist.load_data()
print(type(dataset))
print(len(dataset))

# Getting the train test datasets
training = dataset[0]
testing = dataset[1]

# Getting the input and output of train
print(training[0].shape) # (60000, 28, 28) = (samples, height, weight)
print(training[1].shape)
print(testing[0].shape)
print(testing[1].shape)

# x and y
x_train = training[0]
y_train = training[1]
x_test = testing[0]
y_test = testing[1]

# NOT APPLIED FOR THIS PROBLEM

# Resize to the range [0,1)

def show_size_list(x,h,w):
  ans = []
  for i in range(h):
    for j in range(w):
      ans.append(x[i][j])
  return ans

print(show_size_list(x_train[0],28,28))
x_train, x_test = x_train/255, x_test/255
print(show_size_list(x_train[0],28,28))

# NOT APPLIED FOR THIS PROBLEM

# Add a channel = "1", (28,28) ==> (28,28,1), since we need to convert grayscale to RGB, first we need to attach dimension=1 as by default grayscale is (10000, 28,28) instead of (10000,28,28,1)

# method-1
import tensorflow as tf
def method_1(x_train):
  print("Initial channel: ",x_train.shape)
  x_train_1 = tf.expand_dims(input=x_train, axis=-1) # axis=0 is adding batch_size, axis=-1 is adding channel
  print("New channel: ", x_train_1.shape)
  print(type(x_train_1), "\n")
  return x_train_1
# method-2
import numpy as np
def method_2(x_train):
  print("Initial shape: ", x_train.shape)
  x_train_2 = np.expand_dims(x_train, axis=-1)
  print("New shape: ", x_train_2.shape)
  print(type(x_train_2), "\n")
  return x_train_2
# method-3
import numpy as np
def method_3(x_train):
  print("Initial shape: ", x_train.shape)
  x_train_3 = x_train[..., np.newaxis]
  print("New shape: ", x_train_3.shape)
  print(type(x_train_3), "\n")
  return x_train_3

# NOT APPLIED FOR THIS PROBLEM

# Reshape the data (28,28,1) to (224,224,3)

# Since the size is pretty high, lets just consider a few images
x_train_new = x_train_new[:1000]
y_train_new = y_train_new[:1000]

# method-1: via tf
print("Initial shape: ", x_train_new.shape, y_train_new.shape)
"""
Note:
1. When you are resizing images using tf, tf expects: [batch_size, height, width, channels] in resize, i.e. it needs a batch_size
2. Default it accepts syntax: [height, width]
3. If dealing with a single photo, there is no batch_number, we have (224,224,1) rather than (1,224,224,1) [kinda like GRAYSCALE: (10000,224,224) rather than (10000,224,224,1)]
Thus there is a requirement to specify by expanding the batch size, x_train_1 = tf.image.resize(x_train, (224,224)) - So this usually works, but since working with single image, specify batch_dimensions
"""
# method-1a: when dealing with batch images
import tensorflow as tf
def method_1a(x_train):
  print(x_train.shape)
  x_train_1 = tf.image.resize(x_train, (32,32))
  print(x_train_1.shape)
  return x_train_1
# method-1b: when dealing with single image
def method_1b(x_train):
  x_train = tf.expand_dims(x_train, axis=0) # we need to attach a batch: 1 like axis=-1 for grayscale
  import tensorflow as tf
  x_train_2 = tf.image.resize(images=x_train, size=[32, 32])
  print(x_train_2.shape)
  return x_train_2

# method-2: Resizes images to a target size and pads if necessary to fit the exact dimensions.
import tensorflow as tf
def method_2(x_train):
  print(x_train.shape)
  x_train_3 = tf.image.resize_with_pad(image=x_train, target_height=32, target_width=32)
  print(x_train_3.shape)
  return x_train_3

# method-3: cv2

# method-4: PIL

# Below, these are not right approach, bcz reshape is on arrays, while resize is on images
"""
# method-2
import numpy as np
print(x_train.shape)
x_train_2 = np.reshape(x_train, (60000, 224, 224, 1))
print(x_train_2.shape)
# method-3
import numpy as np
print(x_train.shape)
x_train_3 = x_train.reshape((60000, 224, 224, 1))
print(x_train_3.shape)
"""

# NOT APPLIED FOR THIS PROBLEM

# convert to RGB

import numpy as np
import tensorflow as tf

def G2R(x_train):
  print(x_train.shape)
  x_train_1 = tf.image.grayscale_to_rgb(x_train)
  print(x_train_1.shape)
  return x_train_1
def R2G(x_train):
  print(x_train.shape)
  x_train_2 = tf.image.rgb_to_grayscale(x_train_1)
  print(x_train_2.shape)
  return x_train_2

# Preprocess the data all in 1 place for both test and train

def preprocess_MNIST_test(x,y):

  print(x.shape, y.shape)
  # Scale them down
  x = x/255
  print(x.shape, y.shape)

  print(x.shape, y.shape)
  # Add the channel dimension
  x = tf.expand_dims(x, axis=-1)
  # y = tf.expand_dims(y, axis=-1)

  print(x.shape, y.shape)
  # Resize the x, to (32,32)
  x = x = tf.image.resize(x, (32,32))

  # print(x.shape, y.shape)
  # # Convert to RGB
  # x = tf.image.grayscale_to_rgb(x)

  print(x.shape, y.shape)
  return x,y


x_test_new, y_test_new = preprocess_MNIST_test(x_test, y_test)
x_train_new, y_train_new = preprocess_MNIST_test(x_train, y_train)

"""# Model Import"""

# NOT APPLIED FOR THIS PROBLEM

from tensorflow.keras.applications import ResNet50
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Flatten
# Note:
"""
1. ResNet is specifically trained for image datasets - ImageNet type datasets
2. The recommended input size of images must be (224, 224, 3), rather than mentioning the input_size in ResNet during transfer leaning
3. So there are two approaches when using the image size (28,28,1) on a ResNet.
      a. During ResNet base_model making, we include input_size = (28,28,1) ===> Fine-tuning a model with significantly different input sizes may not leverage the pre-trained features
      b. Change the dataset to size (224,224,3) and then feed it to model =====> You effectively use the features learned by the pre-trained ResNet model without altering its architecture.

"""

# Call the base model
base_model = ResNet50(weights='imagenet',include_top=False,input_shape=(224,224,3), name="rs1")

# Freeze the base model
base_model.trainable = False

# Add customlayers
x = base_model.output
x = tf.keras.layers.Flatten()(x)
x = tf.keras.layers.Dense(10, activation="softmax")(x)

# Compile teh model
model = tf.keras.Model(inputs=base_model.input, outputs=x)
# weights = This specifies which weights to load into the model.
# include_top = This parameter indicates whether to include the fully connected (dense) layer at the top of the model
# input_shape=(224,224,3) = This specifies the shape of the input images.
# classes=11 = This specifies the number of classes for the classification task.
# classifier_activation='softmax' = This defines the activation function used in the final dense layer for classification.
# pooling=None: This parameter determines how to pool the output of the last convolutional layer before the dense layers. Options include:
# # # None: No pooling is applied; the output will be a 4D tensor of shape (batch_size, height, width, filters).
# # # 'avg': Applies average pooling to the output, resulting in a 2D tensor of shape (batch_size, filters).
# # # 'max': Applies max pooling to the output, also resulting in a 2D tensor of shape (batch_size, filters).



# name = This is a name given to the model.
model.summary()

# Make the model, since ResNet is too complex for MNIST

from tensorflow.keras.layers import Conv2D, Flatten, Dense, AveragePooling2D, GlobalAveragePooling2D, MaxPooling2D
from tensorflow.keras.models import Model

"""
# Note:
1. AveragePooling2D: Runs the avg pooling on the feature map outputting a spatially reduced dimensions of the feature map
2. GlobalAveragePooling2D: Runs the avg pooling over the entire final feature maps outputting a single value
"""

class MNIST_model(tf.keras.Model):
  def __init__(self):
    super(MNIST_model, self).__init__()
    self.conv1 = Conv2D(filters=6, kernel_size=(5,5), activation="tanh", input_shape=(32,32,1))
    self.pool1 = AveragePooling2D(pool_size=(2,2))
    self.conv2 = Conv2D(filters=16, kernel_size=(5,5), activation="tanh")
    self.pool2 = AveragePooling2D(pool_size=(2,2))
    self.conv3 = Conv2D(filters=120, kernel_size=(5,5), activation="tanh")
    self.pool3 = GlobalAveragePooling2D()
    self.dense1 = Dense(84, activation="tanh")
    self.dense2 = Dense(10, activation="softmax")

  def call(self, inputs):
    x = self.conv1(inputs)
    x = self.pool1(x)
    x = self.conv2(x)
    x = self.pool2(x)
    x = self.conv3(x)
    x = self.pool3(x)
    x = self.dense1(x)
    return self.dense2(x)

"""# Model compile"""

from tensorflow.keras.optimizers import Adam

model = MNIST_model()

optimizer = Adam(learning_rate=0.001)
loss='sparse_categorical_crossentropy' # requires no one-hot-encoing oof teh target varible, whereas categorical_crossentropy does expect target variables in one-hot-encoded format
metrics=['accuracy']

model.compile(optimizer=optimizer, loss=loss, metrics=metrics)

# Ensuring the shapes are compatible

# When using Keras API, the required dimensions are:
### x = (batch_size, height, width, depth)
### y = (batch_size,)
print(x_train_new.shape)
print(y_train_new.shape)
print(x_test_new.shape)
print(y_test_new.shape)

model.fit(x=x_train_new[:10000], y=y_train_new[:10000], batch_size=32, epochs=3, shuffle=True, verbose=2, validation_data=(x_test_new[:1000], y_test_new[:1000]))


# x = inputs, y=labels
# batch_size = under each epoch, the data samples are divided into sets of size=batch_size and does all forward and backward pass for each set. ==> iterations = [samples/batch_size]
# epoch = no of iterations. ===> Total training = (epoch * iterations)
# shuffle = The shuffle parameter determines whether the data should be shuffled (randomized) before being divided into batches for each epoch
# verbose = 0,1,2 on how output format is required

import numpy as np

output = model.predict(x_test_new[:1])
print(y_test_new[:1])
np.argmax(output, axis=-1)

"""# Try on new data"""

# Method-1

import cv2
import numpy as np
import tensorflow as tf
from google.colab.patches import cv2_imshow

def preprocess(image):
  image = image/255
  image = tf.expand_dims(image,axis=0)
  image = tf.image.resize(image, (32,32))
  image = tf.image.rgb_to_grayscale(image)
  return image


# Load the image
image = cv2.imread("/content/5.webp")
# optional: image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # Convert BGR to RGB, cv2 reads image in BGR format
print("Original Image Shape:", image.shape)

# Display the image
cv2_imshow(image)

# Preprocess the image
image = preprocess(image)
print("Preprocessed Image Shape:", image.shape)

# Display the image
# cv2 expects shape: (height, width, channel)
# plt expects shape: (height, width)
image_np = tf.squeeze(image) # to remove the 1's in the shape
# optional: image_np = tf.image.convert_image_dtype(image_np, dtype=tf.uint8) # Rescale the image back to [0, 255] for display
print(image_np.shape)
# Display the image: as cv2 expects 3 dims: (h, w, ch)
plt.imshow(image_np, cmap="gray")


# Prediction
output = model.predict(image)
np.argmax(output, axis=-1)